{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ndmg Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial provides a basic overview of how to run ndmg manually within Python.\n",
    "The absolute easiest way is to run the pipeline from the command line once all dependencies are installed using the following command:\n",
    "\n",
    "`ndmg_bids </absolute/input/dir> </absolute/output/dir>`.\n",
    "\n",
    "This will run a single session from the input directory, and output the results into your output directory.\n",
    "\n",
    "In the first half of the tutorial, we dive more deeply into what this command is doing under the hood. <br>\n",
    "In the second half of the tutorial, we explore some sample code which runs the pipeline on entire datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. First, we grab some test data and atlases from our github repository. <br>\n",
    "2. Then, we choose our input parameters (the defaults work fine if you don't want to worry about this!) <br>\n",
    "3. Last, we run the pipeline.\n",
    "\n",
    "Running the pipeline is quite simple: call `ndmg_dwi_pipeline.ndmg_dwi_worker` with the correct input flags.\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/ndmg/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import glob\n",
    "import shutil\n",
    "import warnings\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "from ndmg.scripts import ndmg_dwi_pipeline\n",
    "from ndmg.utils import s3_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download test data, atlases, and check for dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code will grab some sample diffusion MRI data from our `neuroparc` repository, as well as the atlases ndmg needs to run. <br>\n",
    "If you want to explore these data and atlases, you can find it in `~/.ndmg/`.\n",
    "\n",
    "Note that the below code requires `git lfs` to be installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure that AFNI and FSL are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your fsl directory is located here: /usr/local/fsl\n",
      "Your AFNI directory is located here: /Users/alex/abin/afni\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FSL\n",
    "try:\n",
    "    print(f\"Your fsl directory is located here: {os.environ['FSLDIR']}\")\n",
    "except KeyError:\n",
    "    raise AssertionError(\"You do not have FSL installed! See installation instructions here: https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FslInstallation\")\n",
    "    \n",
    "# AFNI\n",
    "try:\n",
    "    print(f\"Your AFNI directory is located here: {subprocess.check_output('which afni', shell=True, universal_newlines=True)}\")\n",
    "except subprocess.CalledProcessError:\n",
    "    raise AssertionError(\"You do not have AFNI installed! See installation instructions here: https://afni.nimh.nih.gov/pub/dist/doc/htmldoc/background_install/main_toc.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: 'git lfs clone' is deprecated and will not be updated\n",
      "          with new flags from 'git clone'\n",
      "\n",
      "'git clone' has been updated in upstream Git to have comparable\n",
      "speeds to 'git lfs clone'.\n",
      "Cloning into 'neuroparc'...\n",
      "remote: Enumerating objects: 132, done.\u001b[K\n",
      "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
      "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
      "remote: Total 549 (delta 33), reused 112 (delta 22), pack-reused 417\u001b[K\n",
      "Receiving objects: 100% (549/549), 6.41 MiB | 16.34 MiB/s, done.\n",
      "Resolving deltas: 100% (88/88), done.\n",
      "Downloading LFS objects: 100% (220/220), 288 MB | 47 MB/s                       \r"
     ]
    }
   ],
   "source": [
    "# Make data directory if it doesn't exist\n",
    "ndmg_dir = Path.home() / \".ndmg/\"\n",
    "data_dir = ndmg_dir / \"data/\"\n",
    "\n",
    "# Remove old data if it exists\n",
    "if data_dir.is_dir():\n",
    "    shutil.rmtree(data_dir)\n",
    "    \n",
    "# Remove neuroparc if it already exists\n",
    "if Path(\"neuroparc\").is_dir():\n",
    "    shutil.rmtree(\"neuroparc\")\n",
    "    \n",
    "# Clone the sample data into `~/.ndmg`.\n",
    "data_dir.mkdir(parents=True)\n",
    "!git lfs clone https://github.com/neurodata/neuroparc.git\n",
    "shutil.move(\"neuroparc/data/BNU1\", data_dir)\n",
    "data_dir = data_dir / \"BNU1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Atlases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old atlas dir if it exists\n",
    "atlas_dir = ndmg_dir / \"ndmg_atlases\"\n",
    "if atlas_dir.is_dir():\n",
    "    shutil.rmtree(atlas_dir)\n",
    "\n",
    "# Download atlases to atlas_dir\n",
    "atlas_dir.mkdir(parents=True)\n",
    "for name in Path(\"neuroparc\").iterdir():\n",
    "    shutil.move(str(name), atlas_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove our now-empty directory\n",
    "shutil.rmtree(\"neuroparc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose input parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naming Conventions\n",
    "Here, we define input variables to the pipeline.\n",
    "To run the `ndmg` pipeline, you need four files:\n",
    "1. a `t1w` - this is a high-resolution anatomical image.\n",
    "2. a `dwi` - the diffusion image.\n",
    "3. bvecs - this is a text file that defines the gradient vectors created by a DWI scan.\n",
    "4. bvals - this is a text file that defines magnitudes for the gradient vectors created by a DWI scan.\n",
    "\n",
    "The naming convention is in the [BIDs](https://bids.neuroimaging.io/) spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alex/.ndmg/data/BNU1/sub-0025864/ses-1/anat/sub-0025864_ses-1_T1w.nii.gz\n",
      "/Users/alex/.ndmg/data/BNU1/sub-0025864/ses-1/dwi/sub-0025864_ses-1_dwi.nii.gz\n",
      "/Users/alex/.ndmg/data/BNU1/sub-0025864/ses-1/dwi/sub-0025864_ses-1_dwi.bvec\n",
      "/Users/alex/.ndmg/data/BNU1/sub-0025864/ses-1/dwi/sub-0025864_ses-1_dwi.bval\n"
     ]
    }
   ],
   "source": [
    "# Specify base directory and paths to input files (dwi, bvecs, bvals, and t1w required)\n",
    "subject_id = 'sub-0025864'\n",
    "\n",
    "# Define the location of our input files.\n",
    "t1w = str(data_dir / f\"{subject_id}/ses-1/anat/{subject_id}_ses-1_T1w.nii.gz\")\n",
    "dwi = str(data_dir / f\"{subject_id}/ses-1/dwi/{subject_id}_ses-1_dwi.nii.gz\")\n",
    "bvecs = str(data_dir / f\"{subject_id}/ses-1/dwi/{subject_id}_ses-1_dwi.bvec\")\n",
    "bvals = str(data_dir / f\"{subject_id}/ses-1/dwi/{subject_id}_ses-1_dwi.bval\")\n",
    "\n",
    "print(t1w)\n",
    "print(dwi)\n",
    "print(bvecs)\n",
    "print(bvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Choices\n",
    "Here, we choose the parameters to run the pipeline with.\n",
    "If you are inexperienced with diffusion MRI theory, feel free to just use the default parameters.\n",
    "\n",
    "- *atlases = ['desikan', 'CPAC200', 'DKT', 'HarvardOxfordcort', 'HarvardOxfordsub', 'JHU', 'Schaefer2018-200', 'Talairach', 'aal', 'brodmann', 'glasser', 'yeo-7-liberal', 'yeo-17-liberal']* : The atlas that defines the node location of the graph you create.\n",
    "- *mod_types = ['det', 'prob']* : Deterministic or probablistic tractography.\n",
    "- *track_types = ['local', 'particle']* : Local or particle tracking.\n",
    "- *mods = ['csa', 'csd']* : [Constant Solid Angle](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4360965/) or [Constrained Spherical Deconvolution](https://onlinelibrary.wiley.com/doi/10.1002/ima.22005).\n",
    "- regs = *['native', 'native_dsn', 'mni']* : Registration style. If native, do all registration in each scan's space; if mni, register scans to the MNI atlas; if native_dsn, do registration in native space, and then fit the streamlines to MNI space.\n",
    "- vox_size = *['1mm', '2mm']* : Whether our voxels are 1mm or 2mm.\n",
    "- seeds = int : Seeding density for tractography. More seeds generally results in a better graph, but at a much higher computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your output directory will be : /tmp/output_desikan_det_local_csd_20_native_sub-0025864\n"
     ]
    }
   ],
   "source": [
    "# Use the default parameters.\n",
    "atlas = 'desikan'\n",
    "mod_type = 'det'\n",
    "track_type = 'local'\n",
    "mod_func = 'csd'\n",
    "reg_style = 'native'\n",
    "vox_size = '2mm'\n",
    "seeds = 20\n",
    "\n",
    "# Set an output directory\n",
    "outdir = '/tmp/output_{}_{}_{}_{}_{}_{}_{}'.format(atlas, mod_type, track_type, mod_func, seeds, reg_style, subject_id)\n",
    "print(f\"Your output directory will be : {outdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get masks and labels\n",
    "The pipeline needs these two variables as input. <br>\n",
    "Running the pipeline via `ndmg_bids` does this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask location : /Users/alex/.ndmg/ndmg_atlases/atlases/mask/MNI152NLin6_res-2x2x2_T1w_descr-brainmask.nii.gz\n",
      "atlas location : ['/Users/alex/.ndmg/ndmg_atlases/atlases/label/Human/desikan_space-MNI152NLin6_res-2x2x2.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "# Auto-set paths to neuroparc files\n",
    "mask = str(atlas_dir / \"atlases/mask/MNI152NLin6_res-2x2x2_T1w_descr-brainmask.nii.gz\")\n",
    "labels = [str(i) for i in (atlas_dir / \"atlases/label/Human/\").glob(f\"*{atlas}*2x2x2.nii.gz\")]\n",
    "\n",
    "print(f\"mask location : {mask}\")\n",
    "print(f\"atlas location : {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndmg_dwi_pipeline.ndmg_dwi_worker(dwi=dwi, bvals=bvals, bvecs=bvecs, t1w=t1w, atlas=atlas, mask=mask, labels=labels, outdir=outdir, vox_size=vox_size, mod_type=mod_type, track_type=track_type, mod_func=mod_func, seeds=seeds, reg_style=reg_style, clean=False, skipeddy=True, skipreg=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
