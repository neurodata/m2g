{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running ndmg : One Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial provides a basic overview of how to run ndmg manually within Python.\n",
    "The absolute easiest way is to run the pipeline from the command line once all dependencies are installed using the following command:\n",
    "\n",
    "`ndmg_bids </absolute/input/dir> </absolute/output/dir>`.\n",
    "\n",
    "This will run a single session from the input directory, and output the results into your output directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. First, we grab some test data and atlases from our github repository. <br>\n",
    "2. Then, we choose our input parameters (the defaults work fine if you don't want to worry about this!) <br>\n",
    "3. Last, we run the pipeline.\n",
    "\n",
    "Running the pipeline is quite simple: call `ndmg_dwi_pipeline.ndmg_dwi_worker` with the correct input flags.\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import glob\n",
    "import shutil\n",
    "import warnings\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "from ndmg.scripts import ndmg_dwi_pipeline\n",
    "from ndmg.utils import s3_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download test data, atlases, and prerequisites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code will grab some sample diffusion MRI data from our `neuroparc` repository, as well as the atlases ndmg needs to run. <br>\n",
    "If you want to explore these data and atlases, you can find it in `~/.ndmg/`.\n",
    "\n",
    "Note that the below code requires `git lfs` to be installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure that AFNI and FSL are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your fsl directory is located here: /usr/local/fsl\n",
      "b'/Users/alex/abin/afni\\n'\n"
     ]
    }
   ],
   "source": [
    "# FSL\n",
    "try:\n",
    "    print(f\"Your fsl directory is located here: {os.environ['FSLDIR']}\")\n",
    "except KeyError:\n",
    "    print(\"You do not have FSL installed!\")\n",
    "    \n",
    "# AFNI\n",
    "try:\n",
    "    print(f\"Your AFNI directory is located here: {subprocess.check_output('which afni', shell=True)}\")\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"You do not have AFNI installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data directory if it doesn't exist\n",
    "ndmg_dir = Path.home() / \".ndmg/\"\n",
    "data_dir = ndmg_dir / \"data/\"\n",
    "\n",
    "# Remove old data if it exists\n",
    "if data_dir.is_dir():\n",
    "    shutil.rmtree(data_dir)\n",
    "    \n",
    "# Remove neuroparc if it already exists\n",
    "if Path(\"neuroparc\").is_dir():\n",
    "    shutil.rmtree(\"neuroparc\")\n",
    "    \n",
    "# Clone the sample data into `~/.ndmg`.\n",
    "data_dir.mkdir(parents=True)\n",
    "!git lfs clone https://github.com/neurodata/neuroparc.git\n",
    "shutil.move(\"neuroparc/data/BNU1\", data_dir)\n",
    "data_dir = data_dir / \"BNU1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Atlases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old atlas dir if it exists\n",
    "atlas_dir = ndmg_dir / \"ndmg_atlases\"\n",
    "if atlas_dir.is_dir():\n",
    "    shutil.rmtree(atlas_dir)\n",
    "\n",
    "# Download atlases to atlas_dir\n",
    "atlas_dir.mkdir(parents=True)\n",
    "for name in Path(\"neuroparc\").iterdir():\n",
    "    shutil.move(str(name), atlas_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove our now-empty directory\n",
    "shutil.rmtree(\"neuroparc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose input parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naming Conventions\n",
    "Here, we define input variables to the pipeline.\n",
    "To run the `ndmg` pipeline, you need four files:\n",
    "1. a `t1w` - this is a high-resolution anatomical image.\n",
    "2. a `dwi` - the diffusion image.\n",
    "3. bvecs - this is a text file that defines the gradient vectors created by a DWI scan.\n",
    "4. bvals - this is a text file that defines magnitudes for the gradient vectors created by a DWI scan.\n",
    "\n",
    "The naming convention is in the [BIDs](https://bids.neuroimaging.io/) spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify base directory and paths to input files (dwi, bvecs, bvals, and t1w required)\n",
    "subject_id = 'sub-0025864'\n",
    "\n",
    "# Define the location of our input files.\n",
    "t1w = str(data_dir / f\"{subject_id}/ses-1/anat/{subject_id}_ses-1_T1w.nii.gz\")\n",
    "dwi = str(data_dir / f\"{subject_id}/ses-1/dwi/{subject_id}_ses-1_dwi.nii.gz\")\n",
    "bvecs = str(data_dir / f\"{subject_id}/ses-1/dwi/{subject_id}_ses-1_dwi.bvec\")\n",
    "bvals = str(data_dir / f\"{subject_id}/ses-1/dwi/{subject_id}_ses-1_dwi.bval\")\n",
    "\n",
    "print(t1w)\n",
    "print(dwi)\n",
    "print(bvecs)\n",
    "print(bvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Choices\n",
    "Here, we choose the parameters to run the pipeline with.\n",
    "If you are inexperienced with diffusion MRI theory, feel free to just use the default parameters.\n",
    "\n",
    "- *atlases = ['desikan', 'CPAC200', 'DKT', 'HarvardOxfordcort', 'HarvardOxfordsub', 'JHU', 'Schaefer2018-200', 'Talairach', 'aal', 'brodmann', 'glasser', 'yeo-7-liberal', 'yeo-17-liberal']* : The atlas that defines the node location of the graph you create.\n",
    "- *mod_types = ['det', 'prob']* : Deterministic or probablistic tractography.\n",
    "- *track_types = ['local', 'particle']* : Local or particle tracking.\n",
    "- *mods = ['csa', 'csd']* : [Constant Solid Angle](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4360965/) or [Constrained Spherical Deconvolution](https://onlinelibrary.wiley.com/doi/10.1002/ima.22005).\n",
    "- regs = *['native', 'native_dsn', 'mni']* : Registration style. If native, do all registration in each scan's space; if mni, register scans to the MNI atlas; if native_dsn, do registration in native space, and then fit the streamlines to MNI space.\n",
    "- vox_size = *['1mm', '2mm']* : Whether our voxels are 1mm or 2mm.\n",
    "- seeds = int : Seeding density for tractography. More seeds generally results in a better graph, but at a much higher computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the default parameters.\n",
    "atlas = 'desikan'\n",
    "mod_type = 'det'\n",
    "track_type = 'local'\n",
    "mod_func = 'csd'\n",
    "reg_style = 'native'\n",
    "vox_size = '2mm'\n",
    "seeds = 20\n",
    "\n",
    "# Set an output directory\n",
    "outdir = '/tmp/output_{}_{}_{}_{}_{}_{}_{}'.format(atlas, mod_type, track_type, mod_func, seeds, reg_style, subject_id)\n",
    "print(f\"Your output directory will be : {outdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get masks and labels\n",
    "The pipeline needs these two variables as input. <br>\n",
    "Running the pipeline via `ndmg_bids` does this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-set paths to neuroparc files\n",
    "mask = str(atlas_dir / \"atlases/mask/MNI152NLin6_res-2x2x2_T1w_descr-brainmask.nii.gz\")\n",
    "labels = [str(i) for i in (atlas_dir / \"atlases/label/Human/\").glob(f\"*{atlas}*2x2x2.nii.gz\")]\n",
    "\n",
    "print(f\"mask location : {mask}\")\n",
    "print(f\"atlas location : {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndmg_dwi_pipeline.ndmg_dwi_worker(dwi=dwi, bvals=bvals, bvecs=bvecs, t1w=t1w, atlas=atlas, mask=mask, labels=labels, outdir=outdir, vox_size=vox_size, mod_type=mod_type, track_type=track_type, mod_func=mod_func, seeds=seeds, reg_style=reg_style, clean=False, skipeddy=True, skipreg=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
